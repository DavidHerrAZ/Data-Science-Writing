{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing A Data Science Blog Post\n",
    "## \n",
    "\n",
    "### By: David Herr\n",
    "### Dated: August 2nd, 2020\n",
    "\n",
    "A Jupyter notebook aimed to complete the Udacity Data Science Nanodegree Project 1. In the project, students are to use the CRISP-DM process to understand, prepare, model, and evaluate data to answer real-world business questions.\n",
    "\n",
    "First, we'll bring in the packages used to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import and manipulation \n",
    "import pandas as pd\n",
    "\n",
    "# plotting and graphing\n",
    "%matplotlib inline\n",
    "\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# custom modules\n",
    "import fns_DataVisualization as viz\n",
    "import fns_DataWrangling as DataWrngl\n",
    "import fns_TextWrangling as TxtWrngl\n",
    "\n",
    "#temp library\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Pick A Dataset\n",
    "\n",
    "Although the traditional CRISP-DM path is to start with business questions, the Udacity Data Science program provided datasets to start with. Thus, we'll start with those datasets and read them in to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Boston dataset\n",
    "df_boston = pd.read_csv('./_data/listings_boston.csv')\n",
    "\n",
    "# Read in Seattle dataset\n",
    "df_seattle = pd.read_csv('./_data/listings_seattle.csv')\n",
    "\n",
    "# Place dataframes in list for bulk analysis\n",
    "df_list = [df_boston,df_seattle]\n"
   ]
  },
  {
   "source": [
    "### 2) Pose 3-5 Business Questions\n",
    "Leveraging this data, we are curious to find out if:\n",
    "\n",
    "    1. Bedroom or Bathroom count generally correlates to higher pricing?\n",
    "    2. Are there certain neighborhoods which command generally higher pricing?\n",
    "    3. Does containing a top N keyword in descriptions result in higher pricing?\n",
    "    4. Are ratings predictive of pricing?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 3) Use CRISP_DM \n",
    "To answer these questions, we'll use what is known as the CRISP_DM process. This process is pictated below:\n",
    "\n",
    "![Image of CRISP_DM](_img\\CRISP_DM.png)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "##### 3.1) Business Understanding\n",
    "\n",
    "**Boston Bed/Bath Analysis**\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns to be used for price vs. bed/bath analysis\n",
    "bed_bath_cols = ['price','bedrooms','bathrooms','beds','bed_type']\n",
    "\n",
    "# call 2x2 price analysis plot for all bed/bath cols (Boston)\n",
    "viz.price_analysis_plots(df_boston[bed_bath_cols])"
   ]
  },
  {
   "source": [
    "**Boston Neighborhood Analysis**\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns to be used for price vs. neighbourhood analysis\n",
    "neighborhood_cols = ['price','neighbourhood_cleansed']\n",
    "\n",
    "# call 1x1 price analysis plot for neighborhoods cols (Boston)\n",
    "viz.price_analysis_plots(df_boston[neighborhood_cols], False)"
   ]
  },
  {
   "source": [
    "##### 3.2) Data Understanding\n",
    "\n",
    "While the head() method is useful, a more thorough understanding of all the available columns, datatypes, as well as profile of that data, is necessary before moving on to preparing the data for modeling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# And see the overall shape of each data frame, column names, and column data types\n",
    "DataWrngl.print_column_types(df_list)"
   ]
  },
  {
   "source": [
    "##### 3.3) Data Preperation\n",
    "In this section, we will be using our above observations to guide both the initial cleansing of our data, as well as initial transformations for feature creation.\n",
    "\n",
    "**Column Cleansing**\n",
    "***\n",
    "\n",
    "We'll start with the data cleansing process on the columns. This will largely involve removing:\n",
    "\n",
    "- [x]  100% empty\n",
    "- [x]  Columns with 100% of the same value\n",
    "- [x]  Database identifications\n",
    "- [x]  Non-overlapping columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# Start with dropping columns in all data sets that are 100% na\n",
    "DataWrngl.drop_na_columns(df_list)\n",
    "\n",
    "# Define search words to drop common identification column suffixes\n",
    "search_words = ['_id','_url','_scraped']\n",
    "\n",
    "# Invoke function to drop id, url, and scraping columns\n",
    "DataWrngl.drop_ident_columns(df_list,search_words)\n",
    "\n",
    "# Invoke function to drop any columns containing rows with 100% the same data point\n",
    "DataWrngl.drop_same_columns(df_list)\n",
    "\n",
    "# Invoke function to drop non-overlapping columns between two datasets    \n",
    "DataWrngl.drop_nonoverlap_columns(df_list[0],df_list[1])\n",
    "\n",
    "# Check to make sure all columns are overlapping between dataframes\n",
    "sum((df_boston.columns == df_seattle.columns)) / ((len(df_boston.columns) + len(df_seattle.columns)) / 2 ) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row & Data Cleansing**\n",
    "***\n",
    "Next, we'll move into basic *row cleansing* for items we know will break a linear regression model. This includes:\n",
    "\n",
    "- [x]  True/False - transform to a true boolean rather than text \"t\" or \"f\".\n",
    "- [x]  Substantial Text - must be transformed into a text analytics feature.\n",
    "- [ ]  Date Columns - drop or transform into a duration if business questions warrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invoke function to change 't' or 'f' to true Boolean values\n",
    "DataWrngl.cleanse_data_tf_to_boolean(df_list)\n",
    "\n",
    "#  Define text columns which require processing for text analytics\n",
    "text_columns = ['name','summary','space','description','neighborhood_overview', 'notes']\n",
    "\n",
    "# Invoke tokenization as add columns in both dataframes\n",
    "TxtWrngl.tokenize_text_columns(df_list,text_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                         name_tokenized  \\\n0                               [sunny, bungalow, city]   \n1                  [charming, room, pet, friendly, apt]   \n2                          [mexican, folk, art, boston]   \n3     [spacious, sunny, bedroom, suite, historic, home]   \n4                                  [come, home, boston]   \n...                                                 ...   \n3813              [3br, mountain, view, house, seattle]   \n3814            [portage, bay, view, one, bedroom, apt]   \n3815               [private, apartment, view, lake, wa]   \n3816                   [amazing, view, modern, comfort]   \n3817                      [large, lakefront, apartment]   \n\n                                      summary_tokenized  \\\n0     [cozy, sunny, family, home, master, bedroom, h...   \n1     [charming, quiet, room, second, floor, 1910, c...   \n2     [come, stay, friendly, middle, aged, guy, safe...   \n3     [come, experience, comfort, home, away, home, ...   \n4     [comfy, clean, relaxing, home, one, block, awa...   \n...                                                 ...   \n3813  [3br, 2ba, house, boast, incredible, view, oly...   \n3814  [800, square, foot, 1, bedroom, basement, apar...   \n3815  [comfortable, lower, unit, quiet, charming, mi...   \n3816  [cozy, studio, condo, heart, madison, park, la...   \n3817  [hardwood, floor, fireplace, 65, tv, xbox, one...   \n\n                                        space_tokenized  \\\n0     [house, open, cozy, feel, time, living, room, ...   \n1     [small, cozy, quite, room, full, size, bed, am...   \n2     [come, stay, friendly, middle, aged, guy, safe...   \n3     [place, find, boston, small, however, bedroom,...   \n4     [clean, attractive, private, room, one, block,...   \n...                                                 ...   \n3813  [3br, 2ba, house, bright, stylish, wheelchair,...   \n3814  [space, great, view, portage, bay, marine, act...   \n3815                                              [nan]   \n3816  [fully, furnished, unit, accommodate, need, ma...   \n3817                                              [nan]   \n\n                                  description_tokenized  \\\n0     [cozy, sunny, family, home, master, bedroom, h...   \n1     [charming, quiet, room, second, floor, 1910, c...   \n2     [come, stay, friendly, middle, aged, guy, safe...   \n3     [come, experience, comfort, home, away, home, ...   \n4     [comfy, clean, relaxing, home, one, block, awa...   \n...                                                 ...   \n3813  [3br, 2ba, house, boast, incredible, view, oly...   \n3814  [800, square, foot, 1, bedroom, basement, apar...   \n3815  [comfortable, lower, unit, quiet, charming, mi...   \n3816  [cozy, studio, condo, heart, madison, park, la...   \n3817  [hardwood, floor, fireplace, 65, tv, xbox, one...   \n\n                        neighborhood_overview_tokenized  \\\n0     [roslindale, quiet, convenient, friendly, sout...   \n1     [room, roslindale, diverse, primarily, residen...   \n2     [location, roslindale, safe, diverse, boston, ...   \n3     [roslindale, lovely, little, neighborhood, loc...   \n4     [love, proximity, downtown, neighborhood, prid...   \n...                                                 ...   \n3813  [located, near, lot, family, fun, woodland, pa...   \n3814  [neighborhood, quiet, oasis, close, activity, ...   \n3815                                              [nan]   \n3816  [madison, park, offer, peaceful, slow, pace, u...   \n3817                                              [nan]   \n\n                                        notes_tokenized  \n0                                                 [nan]  \n1     [u, cell, phone, text, using, sensitive, conte...  \n2     [scenic, part, boston, couple, big, park, near...  \n3     [please, mindful, property, old, need, treated...  \n4     [one, roommate, life, lower, level, nurse, usu...  \n...                                                 ...  \n3813                                              [nan]  \n3814  [basement, apartment, newer, residential, home...  \n3815                                              [nan]  \n3816                                              [nan]  \n3817                       [also, puppy, boarded, away]  \n\n[7403 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Leverage pre-tokenized text columns to create bag of words dataframe\n",
    "tokenized_text_columns = [column + '_tokenized' for column in text_columns]\n",
    "\n",
    "# define finding top vocab\n",
    "def get_top_vocabulary(dataframe_list,column_list):\n",
    "\n",
    "    tokenized_df = pd.DataFrame()\n",
    "\n",
    "    for dataframe in dataframe_list:\n",
    "        tokenized_df = tokenized_df.append(dataframe[column_list])\n",
    "\n",
    "    # initialize count vectorizer object\n",
    "    vectorizer = CountVectorizer(tokenizer=TxtWrngl.tokenize)\n",
    "\n",
    "    # get counts of each token (word) in text data\n",
    "    top_vocab_vector = vectorizer.fit_transform(tokenized_df)\n",
    "\n",
    "    # Create dataframe to hold vocabulary and count of each item\n",
    "    top_vocab_df = pd.DataFrame((count,word) for word, count in zip(sum(top_vocab_vector.toarray()).tolist(),vectorizer.get_feature_names()))\n",
    "\n",
    "    # Assign column names to new dataframe\n",
    "    top_vocab_df.columns = ['Word', 'Count']\n",
    "\n",
    "    # Convert the top 20 words to a list for feature extraction\n",
    "    top_vocab = top_vocab_df.nlargest(20,'Count')['Word'].tolist()\n",
    "\n",
    "    return top_vocab\n",
    "\n",
    "result = get_top_vocabulary(df_list,tokenized_text_columns)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4) Data Modeling\n",
    "\n",
    "[Outline placeholder for data modeling section]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5) Results Evaluation\n",
    "\n",
    "[Outline placeholder for evaluation of model and possible re-modeling]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.6) Deployment\n",
    "\n",
    "[Outline placeholder for what deployment steps would be]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Conclusion\n",
    "\n",
    "[Outline placeholder for final remarks]"
   ]
  }
 ]
}